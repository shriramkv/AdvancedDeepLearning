{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision pillow --quiet\n"
      ],
      "metadata": {
        "id": "RwJYXbTO7-UI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # PyTorch for deep learning operations\n",
        "import torchvision.models as models  # Pretrained models like ResNet\n",
        "import torchvision.transforms as transforms  # Image transformations\n",
        "from PIL import Image, UnidentifiedImageError  # Image processing and error handling\n",
        "import requests  # HTTP requests to download images and labels\n",
        "from requests.exceptions import RequestException  # Handle connection errors\n",
        "\n",
        "# 1. Load Pretrained ResNet-18 Model\n",
        "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)  # Load ResNet-18 pretrained on ImageNet\n",
        "model.eval()  # Set the model to evaluation mode (faster inference, no gradient calculations)\n",
        "\n",
        "# 2. Image URLs for Batch Processing (Cats and Dogs)\n",
        "# A list of valid image URLs (from Unsplash) to be classified\n",
        "image_urls = [\n",
        "    \"https://images.unsplash.com/photo-1574158622682-e40e69881006\",  # Dog\n",
        "    \"https://images.unsplash.com/photo-1517849845537-4d257902454a\",  # Cat\n",
        "    \"https://images.unsplash.com/photo-1555685812-4b943f1cb0eb\",      # Dog\n",
        "    \"https://images.unsplash.com/photo-1518791841217-8f162f1e1131\"   # Cat\n",
        "]\n",
        "\n",
        "# 3. Transformations for ResNet\n",
        "# Resize, convert to tensor, and normalize images to fit ResNet's input format\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize image to 224x224 (ResNet input size)\n",
        "    transforms.ToTensor(),  # Convert image to tensor (for PyTorch model)\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize with ImageNet mean and std\n",
        "])\n",
        "\n",
        "# 4. Download and Transform Each Image (Skip Invalid and Unreachable URLs)\n",
        "batch_images = []  # List to store transformed images\n",
        "for url in image_urls:\n",
        "    try:\n",
        "        # Send a GET request to download the image\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()  # Raise an error if the request returns a 404 or 500 error\n",
        "\n",
        "        # Open the image from the response stream\n",
        "        image = Image.open(response.raw)\n",
        "\n",
        "        # Apply transformations and add the image to the batch\n",
        "        batch_images.append(transform(image))\n",
        "\n",
        "    except (UnidentifiedImageError, RequestException) as e:\n",
        "        # If the image can't be opened or downloaded, print an error and skip the URL\n",
        "        print(f\"Skipping URL: {url} - {str(e)}\")\n",
        "\n",
        "# Ensure at least one valid image is in the batch, or raise an error\n",
        "if len(batch_images) == 0:\n",
        "    raise ValueError(\"No valid images could be processed. Please check URLs.\")\n",
        "\n",
        "# Stack all valid images into a single batch tensor for model input\n",
        "batch_input = torch.stack(batch_images)\n",
        "\n",
        "# 5. Perform Inference on Batch\n",
        "output = model(batch_input)  # Pass the batch through the model to get predictions\n",
        "\n",
        "# 6. Get Top Predictions for Each Image\n",
        "predicted_classes = torch.argmax(output, dim=1)  # Get the class with the highest score for each image\n",
        "\n",
        "# 7. Download ImageNet Class Labels\n",
        "LABELS_URL = \"https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\"\n",
        "labels = requests.get(LABELS_URL).json()  # Download class index to map predictions to human-readable labels\n",
        "\n",
        "# 8. Map Class Index to Human-Readable Labels\n",
        "for i, class_idx in enumerate(predicted_classes):\n",
        "    class_name = labels[str(class_idx.item())][1]  # Get label for predicted class index\n",
        "    print(f\"Image {i+1}: Predicted Class - {class_name}\")  # Print the predicted class name for each image\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEl-wkTBYcDy",
        "outputId": "55dd4e28-450d-4353-ceb0-1432d3360b8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 1: Predicted Class - tabby\n",
            "Image 2: Predicted Class - pug\n",
            "Image 3: Predicted Class - Egyptian_cat\n",
            "Image 4: Predicted Class - tabby\n"
          ]
        }
      ]
    }
  ]
}